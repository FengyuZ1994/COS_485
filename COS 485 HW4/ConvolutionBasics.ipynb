{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of ConvolutionBasics.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[{"file_id":"1GsOgn2-gvIt7bNrpGHuUXkBj0tA8qTkr","timestamp":1520008655533}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"metadata":{"id":"PXlcovL5Ln3X","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import scipy.signal\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import fetch_mldata\n","import time\n","from IPython import display"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fnhAhLoaLn3b","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# grayscale and inline plotting\n","%matplotlib inline\n","plt.rcParams['image.cmap'] = 'gray'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mdm0MorDLn3d","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# using scipy's 2d convolution function\n","conv = scipy.signal.convolve# modes include \"full\", \"valid\", and \"same\"\n","conv2 = scipy.signal.convolve2d # modes include \"full\", \"valid\", and \"same\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"srMEXV0uln75","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":33},"outputId":"9c834608-2b31-453c-a851-056c8222d592","executionInfo":{"status":"ok","timestamp":1520112646342,"user_tz":300,"elapsed":305,"user":{"displayName":"Fengyu Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112442328420773017950"}}},"cell_type":"code","source":["w = [1, 2, 3]\n","s = [0, 1, 0.5]\n","\n","np.convolve([1, 2, 3], [0, 1, 0.5])"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0. , 1. , 2.5, 4. , 1.5])"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"yULicXEnLn3g","colab_type":"text"},"cell_type":"markdown","source":["### Exercise 1. Complete the following code to implement 1D \"full\" convolution. You need only fill in the question marks."]},{"metadata":{"id":"eUPWyMzyLn3g","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\"\"\"\n","`CONV_FULL` - 1D \"full\" convolution\n","\n","    R = CONV_FULL(W, S) \n","\n","* `W`: 1D array\n","* `S`: 1D array\n","* `R`: \"full\" convolution of W and S\n","\"\"\"\n","def conv_full(w,s):\n","    r = np.zeros(len(w)+len(s)-1)\n","    for i in range(len(w)):\n","        for j in range(len(s)):\n","            r[i+j] += w[i]*s[j]\n","    return r"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bdP2P5IqLn3j","colab_type":"text"},"cell_type":"markdown","source":["### Test your function by comparing with the built-in `conv` function. The output of the following should be true, if your code is correct."]},{"metadata":{"id":"dgU3RLntLn3j","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":33},"outputId":"b5301958-eb27-4df2-cfec-d4f483ff1a2e","executionInfo":{"status":"ok","timestamp":1520112976895,"user_tz":300,"elapsed":283,"user":{"displayName":"Fengyu Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112442328420773017950"}}},"cell_type":"code","source":["a = np.random.rand(10)\n","b = np.random.rand(3)\n","np.isclose(conv_full(a,b), conv(a,b)).all()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"nOI_7WKGLn3l","colab_type":"text"},"cell_type":"markdown","source":["### Exercise 2. Complete the following code to implement 2D \"full\" convolution. You need only fill in the question marks."]},{"metadata":{"id":"RqNNoptJLn3m","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\"\"\"\n","`CONV2_FULL` - 2D \"full\" convolution\n","\n","    R = CONV2_FULL(W, S) \n","\n","* `W`: 2D array\n","* `S`: 2D array\n","* `R`: \"full\" convolution of W and S\n","\"\"\"\n","def conv2_full(w,s):\n","    wsize1, wsize2 = w.shape\n","    ssize1, ssize2 = s.shape\n","    r = np.zeros([wsize1+ssize1-1, wsize2+ssize2-1])\n","    for i1 in range(wsize1):\n","        for i2 in range(wsize2):\n","            for j1 in range(ssize1):\n","                for j2 in range(ssize2):\n","                    r[i1+j1, i2+j2] += w[i1, i2] * s[j1, j2]\n","    return r"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ypD_4hqqLn3o","colab_type":"text"},"cell_type":"markdown","source":["### Test your function by comparing with the built-in `conv2` function. The output of the following should be true, if your code is correct."]},{"metadata":{"id":"3G65OYJkLn3p","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":33},"outputId":"7bab9e51-3e6a-4808-8ef0-d81477a85f5d","executionInfo":{"status":"ok","timestamp":1520113119682,"user_tz":300,"elapsed":243,"user":{"displayName":"Fengyu Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112442328420773017950"}}},"cell_type":"code","source":["a = np.random.rand(10,6)\n","b = np.random.rand(3,2)\n","np.isclose(conv2_full(a,b), conv2(a,b)).all()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"KEsyjxKoLn3r","colab_type":"text"},"cell_type":"markdown","source":["### Exercise 3. In class you learned that 1D convolution is equivalent to multiplication by a Toeplitz matrix, where the size of the matrix depends on the length of the input signal. Complete the following code to construct the matrix. You need only fill in the question marks."]},{"metadata":{"id":"FVP8FiB_Ln3s","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\"\"\"\n","`CONVMTX` - 1D convolution matrix\n","\n","    MTX = CONVMTX(KERNEL, INSIZE) \n","\n","* `KERNEL`: kernel of the convolution\n","* `INSIZE`: length of the input signal\n","* `MTX`: multiplication by MTX is equivalent to convolution by KERNEL\n","\"\"\"\n","def convmtx(kernel, insize, shape = \"full\"):\n","    kernelsize = len(kernel)\n","    outsize = kernelsize + insize - 1 \n","    mtx = np.zeros([outsize, insize])\n","\n","    for i in range(insize):\n","        mtx[i:i+kernelsize, i] = kernel\n","\n","    if shape == \"valid\":\n","        mtx = mtx[kernelsize-1 : insize , :]\n","    \n","    return mtx"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8B3ZpD3DLn3u","colab_type":"text"},"cell_type":"markdown","source":["### Test that multiplication by your matrix is equivalent to convolution. The output of the following should be true, if your code is correct."]},{"metadata":{"id":"qGimFmv1Ln3v","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":33},"outputId":"8074fb0d-acf4-4ae1-91f0-76c24b0d0481","executionInfo":{"status":"ok","timestamp":1520116230468,"user_tz":300,"elapsed":257,"user":{"displayName":"Fengyu Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112442328420773017950"}}},"cell_type":"code","source":["kernel = np.random.rand(3)\n","sig = np.random.rand(7)\n","np.isclose(np.dot(convmtx(kernel,len(sig),\"full\"), sig), conv(kernel,sig,\"full\")).any()"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":16}]},{"metadata":{"id":"i47GAY-OLn3x","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":33},"outputId":"20d9c6e9-658d-4a50-9b77-1fa9f9ffa2f0","executionInfo":{"status":"ok","timestamp":1520116231400,"user_tz":300,"elapsed":268,"user":{"displayName":"Fengyu Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112442328420773017950"}}},"cell_type":"code","source":["np.isclose(np.dot(convmtx(kernel,len(sig),\"valid\"), sig), conv(kernel,sig,\"valid\")).any()"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":17}]},{"metadata":{"id":"arzjPhP6Ln3z","colab_type":"text"},"cell_type":"markdown","source":["### The following illustrates that the transpose of a convolution matrix is equal to a convolution matrix with a flipped kernel. "]},{"metadata":{"id":"UVIzI3sDLn30","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["kernel = np.array([1,2,3])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dp9PVByQLn32","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":66},"outputId":"7dde6c1d-c3d1-4e27-bee2-d4b619f9dc48","executionInfo":{"status":"ok","timestamp":1520116605978,"user_tz":300,"elapsed":216,"user":{"displayName":"Fengyu Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112442328420773017950"}}},"cell_type":"code","source":["convmtx(kernel,5,\"valid\")"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[3., 2., 1., 0., 0.],\n","       [0., 3., 2., 1., 0.],\n","       [0., 0., 3., 2., 1.]])"]},"metadata":{"tags":[]},"execution_count":19}]},{"metadata":{"id":"OJqWdjBhLn35","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":99},"outputId":"2dfa50cc-51fc-40af-c062-bdef116c2c33","executionInfo":{"status":"ok","timestamp":1520116606484,"user_tz":300,"elapsed":207,"user":{"displayName":"Fengyu Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112442328420773017950"}}},"cell_type":"code","source":["convmtx(kernel[::-1],3, \"full\")     # the kernel is flipped"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[3., 0., 0.],\n","       [2., 3., 0.],\n","       [1., 2., 3.],\n","       [0., 1., 2.],\n","       [0., 0., 1.]])"]},"metadata":{"tags":[]},"execution_count":20}]},{"metadata":{"id":"E9j_k6qjLn39","colab_type":"text"},"cell_type":"markdown","source":["There's no coding to do here. Just verify for yourself that the above two matrices are transposes of each other.  Note that transpose changes valid to full, and vice versa. This is why the backward pass for a convolutional net contains flipped kernels. These are equivalent to the transposed matrices in the backward pass for a neural net."]}]}